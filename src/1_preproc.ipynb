{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6ff74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Computing daily overall severity...\n",
      "Building symptom matrix (top 100)...\n",
      "Building condition matrix (top 100)...\n",
      "Building tag matrix (top 100)...\n",
      "Building food matrix (top 100)...\n",
      "Building treatment matrix (top 100)...\n",
      "Extracting weather features (if present)...\n",
      "Combining all daily-level features...\n",
      "Adding demographics...\n",
      "Creating next-day binary label: worse vs not-worse...\n",
      "Number of consecutive-day pairs: 223865\n",
      "Binary label distribution (worse_tomorrow):\n",
      "worse_tomorrow\n",
      "0    0.561\n",
      "1    0.439\n",
      "Name: proportion, dtype: float64\n",
      "Building final X and y...\n",
      "X shape: (223865, 672)\n",
      "y length: 223865\n",
      "Saving preprocessed data...\n",
      "Done! Binary data saved for predicting: worse tomorrow (1) vs same/better (0).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ==============================\n",
    "# CONFIG\n",
    "# ==============================\n",
    "DATA_PATH = \"../data/export.csv\"\n",
    "TOP_SYMPTOMS = 100\n",
    "TOP_CONDITIONS = 100\n",
    "TOP_TAGS = 100\n",
    "TOP_FOODS = 100\n",
    "TOP_TREATMENTS = 100\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 1. LOAD & CLEAN\n",
    "# ==============================\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(\n",
    "    DATA_PATH,\n",
    "    low_memory=False,\n",
    "    parse_dates=[\"checkin_date\"],\n",
    ")\n",
    "\n",
    "# Normalize text fields\n",
    "for col in [\"trackable_type\", \"trackable_name\", \"sex\", \"country\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = (\n",
    "            df[col].astype(str).str.strip().str.lower().replace({\"nan\": pd.NA})\n",
    "        )\n",
    "\n",
    "# Clean age\n",
    "if \"age\" in df.columns:\n",
    "    df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "    df.loc[(df[\"age\"] < 0) | (df[\"age\"] > 120), \"age\"] = pd.NA\n",
    "\n",
    "# Numeric severity conversion\n",
    "df[\"trackable_value_numeric\"] = pd.to_numeric(\n",
    "    df[\"trackable_value\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 2. DAILY OVERALL SEVERITY (SYMPTOMS + CONDITIONS)\n",
    "# ==============================\n",
    "print(\"Computing daily overall severity...\")\n",
    "\n",
    "symptom_mask = df[\"trackable_type\"] == \"symptom\"\n",
    "condition_mask = df[\"trackable_type\"] == \"condition\"\n",
    "\n",
    "symptoms = df[symptom_mask].dropna(subset=[\"trackable_value_numeric\"]).copy()\n",
    "conditions = df[condition_mask].dropna(subset=[\"trackable_value_numeric\"]).copy()\n",
    "\n",
    "severity_df = (\n",
    "    pd.concat([symptoms, conditions], axis=0)\n",
    "    .groupby([\"user_id\", \"checkin_date\"])[\"trackable_value_numeric\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"trackable_value_numeric\": \"overall_symptom_severity\"})\n",
    ")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3. DAILY SYMPTOM MATRIX (TOP 100)\n",
    "# ==============================\n",
    "print(\"Building symptom matrix (top 100)...\")\n",
    "\n",
    "top_symptom_names = (\n",
    "    symptoms[\"trackable_name\"]\n",
    "    .value_counts()\n",
    "    .head(TOP_SYMPTOMS)\n",
    "    .index\n",
    ")\n",
    "\n",
    "symptoms_top = symptoms[symptoms[\"trackable_name\"].isin(top_symptom_names)]\n",
    "\n",
    "daily_symptom_matrix = (\n",
    "    symptoms_top\n",
    "    .groupby([\"user_id\", \"checkin_date\", \"trackable_name\"])[\"trackable_value_numeric\"]\n",
    "    .mean()\n",
    "    .unstack(\"trackable_name\")\n",
    ")\n",
    "\n",
    "daily_symptom_matrix.columns = [f\"symptom_{c}\" for c in daily_symptom_matrix.columns]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4. DAILY CONDITION MATRIX (TOP 100)\n",
    "# ==============================\n",
    "print(\"Building condition matrix (top 100)...\")\n",
    "\n",
    "top_condition_names = (\n",
    "    conditions[\"trackable_name\"]\n",
    "    .value_counts()\n",
    "    .head(TOP_CONDITIONS)\n",
    "    .index\n",
    ")\n",
    "\n",
    "conditions_top = conditions[conditions[\"trackable_name\"].isin(top_condition_names)]\n",
    "\n",
    "daily_condition_matrix = (\n",
    "    conditions_top\n",
    "    .groupby([\"user_id\", \"checkin_date\", \"trackable_name\"])[\"trackable_value_numeric\"]\n",
    "    .mean()\n",
    "    .unstack(\"trackable_name\")\n",
    ")\n",
    "\n",
    "daily_condition_matrix.columns = [f\"condition_{c}\" for c in daily_condition_matrix.columns]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 5. DAILY TAGS (binary, TOP 100)\n",
    "# ==============================\n",
    "print(\"Building tag matrix (top 100)...\")\n",
    "\n",
    "tags = df[df[\"trackable_type\"] == \"tag\"].copy()\n",
    "tags_daily = None\n",
    "\n",
    "if not tags.empty:\n",
    "    top_tag_names = tags[\"trackable_name\"].value_counts().head(TOP_TAGS).index\n",
    "    tags_top = tags[tags[\"trackable_name\"].isin(top_tag_names)].copy()\n",
    "    if not tags_top.empty:\n",
    "        tags_top[\"value\"] = 1\n",
    "        tags_daily = (\n",
    "            tags_top\n",
    "            .groupby([\"user_id\", \"checkin_date\", \"trackable_name\"])[\"value\"]\n",
    "            .max()\n",
    "            .unstack(\"trackable_name\")\n",
    "            .fillna(0)\n",
    "        )\n",
    "        tags_daily.columns = [f\"tag_{c}\" for c in tags_daily.columns]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 6. DAILY FOODS (binary, TOP 100)\n",
    "# ==============================\n",
    "print(\"Building food matrix (top 100)...\")\n",
    "\n",
    "foods = df[df[\"trackable_type\"] == \"food\"].copy()\n",
    "foods_daily = None\n",
    "\n",
    "if not foods.empty:\n",
    "    top_food_names = foods[\"trackable_name\"].value_counts().head(TOP_FOODS).index\n",
    "    foods_top = foods[foods[\"trackable_name\"].isin(top_food_names)].copy()\n",
    "    if not foods_top.empty:\n",
    "        foods_top[\"value\"] = 1\n",
    "        foods_daily = (\n",
    "            foods_top\n",
    "            .groupby([\"user_id\", \"checkin_date\", \"trackable_name\"])[\"value\"]\n",
    "            .max()\n",
    "            .unstack(\"trackable_name\")\n",
    "            .fillna(0)\n",
    "        )\n",
    "        foods_daily.columns = [f\"food_{c}\" for c in foods_daily.columns]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 7. DAILY TREATMENTS (binary, TOP 100)\n",
    "# ==============================\n",
    "print(\"Building treatment matrix (top 100)...\")\n",
    "\n",
    "treatments = df[df[\"trackable_type\"] == \"treatment\"].copy()\n",
    "treatments_daily = None\n",
    "\n",
    "if not treatments.empty:\n",
    "    top_treatment_names = treatments[\"trackable_name\"].value_counts().head(TOP_TREATMENTS).index\n",
    "    treatments_top = treatments[treatments[\"trackable_name\"].isin(top_treatment_names)].copy()\n",
    "    if not treatments_top.empty:\n",
    "        treatments_top[\"value\"] = 1\n",
    "        treatments_daily = (\n",
    "            treatments_top\n",
    "            .groupby([\"user_id\", \"checkin_date\", \"trackable_name\"])[\"value\"]\n",
    "            .max()\n",
    "            .unstack(\"trackable_name\")\n",
    "            .fillna(0)\n",
    "        )\n",
    "        treatments_daily.columns = [f\"treatment_{c}\" for c in treatments_daily.columns]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 8. DAILY WEATHER (all weather fields)\n",
    "# ==============================\n",
    "print(\"Extracting weather features (if present)...\")\n",
    "\n",
    "weather_cols = [c for c in df.columns if c.startswith(\"weather_\")]\n",
    "weather_daily = None\n",
    "\n",
    "if weather_cols:\n",
    "    weather_daily = (\n",
    "        df[[\"user_id\", \"checkin_date\"] + weather_cols]\n",
    "        .drop_duplicates([\"user_id\", \"checkin_date\"])\n",
    "        .set_index([\"user_id\", \"checkin_date\"])\n",
    "        .groupby([\"user_id\", \"checkin_date\"])\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 9. BUILD MASTER DAILY TABLE\n",
    "# ==============================\n",
    "print(\"Combining all daily-level features...\")\n",
    "\n",
    "daily = severity_df.set_index([\"user_id\", \"checkin_date\"])\n",
    "\n",
    "daily = daily.join(daily_symptom_matrix, how=\"left\")\n",
    "daily = daily.join(daily_condition_matrix, how=\"left\")\n",
    "\n",
    "if tags_daily is not None:\n",
    "    daily = daily.join(tags_daily, how=\"left\")\n",
    "\n",
    "if foods_daily is not None:\n",
    "    daily = daily.join(foods_daily, how=\"left\")\n",
    "\n",
    "if treatments_daily is not None:\n",
    "    daily = daily.join(treatments_daily, how=\"left\")\n",
    "\n",
    "if weather_daily is not None:\n",
    "    daily = daily.join(weather_daily, how=\"left\")\n",
    "\n",
    "# Fill binary-like features with 0 (tags/foods/treatments)\n",
    "binary_like_cols = [\n",
    "    c for c in daily.columns\n",
    "    if c.startswith(\"tag_\") or c.startswith(\"food_\") or c.startswith(\"treatment_\")\n",
    "]\n",
    "daily[binary_like_cols] = daily[binary_like_cols].fillna(0)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 10. ADD DEMOGRAPHICS\n",
    "# ==============================\n",
    "print(\"Adding demographics...\")\n",
    "\n",
    "daily = daily.reset_index()\n",
    "\n",
    "demo_cols = [c for c in [\"user_id\", \"age\", \"sex\", \"country\"] if c in df.columns]\n",
    "\n",
    "demo = (\n",
    "    df[demo_cols]\n",
    "    .drop_duplicates(\"user_id\")\n",
    "    .set_index(\"user_id\")\n",
    ")\n",
    "\n",
    "demo = pd.get_dummies(\n",
    "    demo,\n",
    "    columns=[c for c in demo.columns if c in [\"sex\", \"country\"]],\n",
    "    dummy_na=True\n",
    ")\n",
    "\n",
    "daily = daily.set_index(\"user_id\").join(demo, how=\"left\").reset_index()\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 11. NEXT-DAY LABELING (CONSECUTIVE ONLY)\n",
    "# ==============================\n",
    "print(\"Creating next-day binary label: worse vs not-worse...\")\n",
    "\n",
    "# sort by user and date\n",
    "daily = daily.sort_values([\"user_id\", \"checkin_date\"])\n",
    "\n",
    "# drop rows with missing baseline severity\n",
    "daily = daily.dropna(subset=[\"overall_symptom_severity\"])\n",
    "\n",
    "# shift within each user to get next date + severity\n",
    "daily[\"checkin_date_next\"] = daily.groupby(\"user_id\")[\"checkin_date\"].shift(-1)\n",
    "daily[\"next_severity\"] = daily.groupby(\"user_id\")[\"overall_symptom_severity\"].shift(-1)\n",
    "\n",
    "# compute gap in days to ensure true consecutive days\n",
    "daily[\"gap_days\"] = (daily[\"checkin_date_next\"] - daily[\"checkin_date\"]).dt.days\n",
    "\n",
    "# keep only consecutive-day pairs\n",
    "paired = daily[daily[\"gap_days\"] == 1].copy()\n",
    "\n",
    "print(\"Number of consecutive-day pairs:\", len(paired))\n",
    "\n",
    "# delta (for reference/analysis, not used in label now)\n",
    "paired[\"delta\"] = paired[\"next_severity\"] - paired[\"overall_symptom_severity\"]\n",
    "\n",
    "# NEW BINARY LABEL:\n",
    "# 1 if next day is worse (higher severity), else 0\n",
    "paired[\"worse_tomorrow\"] = (paired[\"next_severity\"] > paired[\"overall_symptom_severity\"]).astype(int)\n",
    "\n",
    "print(\"Binary label distribution (worse_tomorrow):\")\n",
    "print(paired[\"worse_tomorrow\"].value_counts(normalize=True).round(3))\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 12. FINAL FEATURE MATRIX\n",
    "# ==============================\n",
    "print(\"Building final X and y...\")\n",
    "\n",
    "exclude_cols = {\n",
    "    \"user_id\",\n",
    "    \"checkin_date\",\n",
    "    \"checkin_date_next\",\n",
    "    \"gap_days\",\n",
    "    \"next_severity\",\n",
    "    \"delta\",\n",
    "    \"worse_tomorrow\",\n",
    "}\n",
    "\n",
    "feature_cols = [c for c in paired.columns if c not in exclude_cols]\n",
    "\n",
    "X = paired[feature_cols]\n",
    "y = paired[\"worse_tomorrow\"]\n",
    "\n",
    "# impute remaining NaNs with column means\n",
    "X = X.apply(lambda col: col.fillna(col.mean()))\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y length:\", len(y))\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 13. SAVE\n",
    "# ==============================\n",
    "print(\"Saving preprocessed data...\")\n",
    "X.to_parquet(\"../results/X.parquet\", index=False)\n",
    "y.to_csv(\"../results/y.csv\", index=False)\n",
    "\n",
    "print(\"Done! Binary data saved for predicting: worse tomorrow (1) vs same/better (0).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdplus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
